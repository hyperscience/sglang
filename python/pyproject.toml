[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

# To build a new wheel, delete (if necessary) build/ and dist/, update the version below and run:
# pip install build
# python -m build --wheel
# this creates a new wheel file under dist/

[project]
name = "sglang"
version = "0.5.4+hs0"
description = "SGLang is a fast serving framework for large language models and vision language models."
readme = "README.md"
requires-python = ">=3.10"
license = { file = "LICENSE" }
classifiers = [
  "Programming Language :: Python :: 3",
  "License :: OSI Approved :: Apache Software License",
]

dependencies = []

[project.optional-dependencies]
cpu = [
  "IPython",
  "aiohttp",
  "anthropic>=0.20.0",
  "blobfile==3.0.0",
  "build",
  "compressed-tensors",
  "datasets",
  "einops",
  "fastapi",
  "hf_transfer",
  "huggingface_hub",
  "interegular",
  "llguidance>=0.7.11,<0.8.0",
  "modelscope",
  "msgspec",
  "ninja",
  "numpy",
  "openai-harmony==0.0.4",
  "openai==1.99.1",
  "orjson",
  "outlines==0.1.11",
  "packaging",
  "partial_json_parser",
  "pillow",
  "prometheus-client>=0.20.0",
  "psutil",
  "py-spy",
  "pybase64",
  "pydantic",
  "python-multipart",
  "pyzmq>=25.1.2",
  "requests",
  "scipy",
  "sentencepiece",
  "setproctitle",
  "soundfile==0.13.1",
  "tiktoken",
  "torchao==0.9.0",
  "tqdm",
  "transformers==4.57.1",
  "uvicorn",
  "uvloop",
]

gpu = [
  "IPython",
  "aiohttp",
  "anthropic>=0.20.0",
  "blobfile==3.0.0",
  "build",
  "compressed-tensors",
  "cuda-python",
  "decord2",
  "datasets",
  "einops",
  "fastapi",
  "flashinfer_python==0.4.1",
  "hf_transfer",
  "huggingface_hub",
  "interegular",
  "llguidance>=0.7.11,<0.8.0",
  "modelscope",
  "msgspec",
  "ninja",
  "numpy",
  "nvidia-cuda-runtime-cu12",  # see https://github.com/sgl-project/sglang/issues/11333#issuecomment-3492260211
  "nvidia-cutlass-dsl==4.2.1",
  "openai-harmony==0.0.4",
  "openai==1.99.1",
  "orjson",
  "outlines==0.1.11",
  "packaging",
  "partial_json_parser",
  "pillow",
  "prometheus-client>=0.20.0",
  "psutil",
  "py-spy",
  "pybase64",
  "pydantic",
  "nvidia-ml-py",
  "python-multipart",
  "pyzmq>=25.1.2",
  "requests",
  "scipy",
  "sentencepiece",
  "setproctitle",
  "sgl-kernel==0.3.16.post3",
  "soundfile==0.13.1",
  "tiktoken",
  "torch==2.8.0",
  "torch_memory_saver==0.0.9",
  "torchao==0.9.0",
  "torchaudio==2.8.0",
  "torchvision",
  "tqdm",
  "transformers==4.57.1",
  "uvicorn",
  "uvloop",
]

modelopt = ["nvidia-modelopt"]
test = [
  "accelerate",
  "expecttest",
  "gguf",
  "jsonlines",
  "matplotlib",
  "pandas",
  "peft",
  "pytest",
  "sentence_transformers",
  "tabulate",
]
checkpoint-engine = ["checkpoint-engine==0.1.2"]
all = []
dev = ["sglang[test]"]

# Temporary tags
cu130 = [
  "torch==2.9.0",
  "torchaudio==2.9.0",
  "torchvision==0.24.0",
]
cu130_all = [
  "sglang[test]",
  "sglang[decord]",
  "sglang[cu130]"
]
tracing = [
  "opentelemetry-api",
  "opentelemetry-exporter-otlp",
  "opentelemetry-exporter-otlp-proto-grpc",
  "opentelemetry-sdk",
]

# To be deprecated in 2 weeks
blackwell = ["sglang[dev]"]
blackwell_aarch64 = ["sglang[dev]"]

[project.urls]
"Homepage" = "https://github.com/sgl-project/sglang"
"Bug Tracker" = "https://github.com/sgl-project/sglang/issues"

[tool.setuptools.package-data]
"sglang" = [
  "srt/layers/moe/fused_moe_triton/configs/*/*.json",
  "srt/layers/quantization/configs/*.json",
  "srt/mem_cache/storage/hf3fs/hf3fs_utils.cpp",
  "srt/speculative/cpp_ngram/*.cpp",
  "srt/speculative/cpp_ngram/*.h",
]

[tool.setuptools.packages.find]
exclude = [
  "assets*",
  "benchmark*",
  "docs*",
  "dist*",
  "playground*",
  "scripts*",
  "tests*",
]

[tool.wheel]
exclude = [
  "assets*",
  "benchmark*",
  "docs*",
  "dist*",
  "playground*",
  "scripts*",
  "tests*",
]

[tool.codespell]
ignore-words-list = "ans, als, hel, boostrap, childs, te, vas, hsa, ment"
skip = "*.json,*.jsonl,*.patch,*.txt"
